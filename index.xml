<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <link>https://labs.yulrizka.com/</link>
    <description>Recent content on </description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Thu, 26 Sep 2019 11:44:50 +0200</lastBuildDate>
    
	<atom:link href="https://labs.yulrizka.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Sort file inline</title>
      <link>https://labs.yulrizka.com/til/unix/sort-file-inline/</link>
      <pubDate>Thu, 26 Sep 2019 11:44:50 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/sort-file-inline/</guid>
      <description>We can sort file by using sort command for example:
$ sort a.txt # or $ cat a.txt | sort  But this will only output to stdout. Some time you want the file to be sorted. Instead you can do
$ sort a.txt -o a.txt  note that this DOEST work and it will TRUNCATE the file
$ sort a.txt &amp;gt; a.txt  </description>
    </item>
    
    <item>
      <title>Show Hidden File</title>
      <link>https://labs.yulrizka.com/til/osx/show-hidden-file/</link>
      <pubDate>Sun, 22 Sep 2019 16:20:01 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/osx/show-hidden-file/</guid>
      <description>Tho show hidden file (file with x):
Mojave:
In finder CMD + Shift + . to toggle it
Before Mojave:
Show
defaults write com.apple.finder AppleShowAllFiles YES; killall Finder /System/Library/CoreServices/Finder.app  Hide
defaults write com.apple.finder AppleShowAllFiles NO; killall Finder /System/Library/CoreServices/Finder.app  </description>
    </item>
    
    <item>
      <title>Bash Forloop</title>
      <link>https://labs.yulrizka.com/til/unix/bash-forloop/</link>
      <pubDate>Mon, 16 Sep 2019 17:19:11 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/bash-forloop/</guid>
      <description>Example of forloop syntax
for i in 1 2 3 4 5 do echo &amp;quot;i=$i&amp;quot; done  with range
for i in {1..5} do echo &amp;quot;i=$i&amp;quot; done  cutomize increment
for i in {0..10..2} do echo &amp;quot;i=$i&amp;quot; done  </description>
    </item>
    
    <item>
      <title>Zsh Ctrl P Same Behavior as Up Arrow</title>
      <link>https://labs.yulrizka.com/til/unix/zsh-ctrl-p-same-behavior-as-up-arrow/</link>
      <pubDate>Fri, 13 Sep 2019 16:26:08 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/zsh-ctrl-p-same-behavior-as-up-arrow/</guid>
      <description>By default Ctrl-P just jump back to the history while up arrow behave a little bit smarter.
For example if you have history like this
ssh a.com ls cd ssh b.com cat grep  Normaly if you type $ ssh and Ctrl-P afterwares, it will give you grep not ssh b.com
to change this behavior, you can put this in your .zshrc
bindkey &amp;quot;^P&amp;quot; up-line-or-beginning-search bindkey &amp;quot;^N&amp;quot; down-line-or-beginning-search  </description>
    </item>
    
    <item>
      <title>extend letsencrypt certificate with DNS challenge</title>
      <link>https://labs.yulrizka.com/til/unix/extend-letsencrypt-certificate-with-dns-challenge/</link>
      <pubDate>Wed, 03 Apr 2019 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/extend-letsencrypt-certificate-with-dns-challenge/</guid>
      <description>Assuming the domain name is yulrizka.com and the certificate was created with
$ certbot certonly --standalone --preferred-challenges dns -d yulrizka.com  To extend this certificate with DNS challenge
# certbot -d yulrizka.com --manual --preferred-challenges dns certonly  You will be asked to add TXT record of _acme-challenge.yulrizka.com.
After updating that DNS record, wait couple of minutes and proceed.</description>
    </item>
    
    <item>
      <title>rename tmux window</title>
      <link>https://labs.yulrizka.com/til/unix/rename-tmux-window/</link>
      <pubDate>Thu, 17 Jan 2019 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/rename-tmux-window/</guid>
      <description>C-a A  That&amp;rsquo;s Control-a A</description>
    </item>
    
    <item>
      <title>DNSSEC</title>
      <link>https://labs.yulrizka.com/til/net/dnssec/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/net/dnssec/</guid>
      <description>DNSSEC  DNSSEC is a technology that was developed to, among other things, protect against such attacks by digitally &amp;lsquo;signing&amp;rsquo; data so you can be assured it is valid. However, in order to eliminate the vulnerability from the Internet, it must be deployed at each step in the lookup from root zone to final domain name (e.g., www.icann.org). Signing the root (deploying DNSSEC on the root zone) is a necessary step in this overall processii.</description>
    </item>
    
    <item>
      <title>reset email multiple git commit</title>
      <link>https://labs.yulrizka.com/til/git/reset-email-multiple-commit/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/git/reset-email-multiple-commit/</guid>
      <description>I started not to use my real email for git commit. Instead i uses the one that is provided by github
After enabling Block command line pushes that expose my email on Block command line pushes that expose my email, it will reject all email that exposes public email adress.
So in order to rewrite git history and change the author email, I found this github help
#!/bin/sh git filter-branch --env-filter &#39; OLD_EMAIL=&amp;quot;your-old-email@example.</description>
    </item>
    
    <item>
      <title>encription with gpg</title>
      <link>https://labs.yulrizka.com/til/unix/encription-with-gpg/</link>
      <pubDate>Sun, 06 Jan 2019 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/encription-with-gpg/</guid>
      <description>Generate key gpg --gen-key  List keys gpg --list-keys  Encrypt Data With a passprhare
gpg -ca -o output.txt.gpg input.txt  with a certificate and from STDOUT
gpg -ea  or if you know the name already (can be key, name or email)
gpg -ea -r &amp;quot;Ahmy&amp;quot;  Decrypt Data gpg -d file.txt.gpg  Export Public key
gpg --export -a &amp;quot;name&amp;quot; &amp;gt; public.key  -a is to create armored ascii output.</description>
    </item>
    
    <item>
      <title>ldap list users</title>
      <link>https://labs.yulrizka.com/til/net/ldap-list-users/</link>
      <pubDate>Wed, 31 Oct 2018 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/net/ldap-list-users/</guid>
      <description> ldap list users On ldap connected machine
$ genet group groupname groupname*:2141:usera,userb,userc,userd  </description>
    </item>
    
    <item>
      <title>zfs external backup drive with snapshot and encryption</title>
      <link>https://labs.yulrizka.com/til/linux/zfs-external-backup-drive-with-snapshot-and-encryption/</link>
      <pubDate>Wed, 24 Oct 2018 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/linux/zfs-external-backup-drive-with-snapshot-and-encryption/</guid>
      <description>main source
Get device id $ ls /dev/disk/by-id -alh ... lrwxrwxrwx 1 root root 10 okt 24 06:06 ata-WDC_WD10EZEX-08M2NA0_WD-WMC3F1471486-part4 -&amp;gt; ../../sda4 ...  For example, I&amp;rsquo;m going to use /dev/disk/by-id/ata-WDC_WD10EZEX-08M2NA0_WD-WMC3F1471486-part4
Setup disk encryption with LUKS setup LuKS
$ sudo apt install cryptsetup $ cryptsetup luksFormat --cipher aes-xts-plain64 --key-size 512 --iter-time 10000 --use-random -y /dev/disk/by-id/ata-WDC_WD10EZEX-08M2NA0_WD-WMC3F1471486-part4   --cipher encryption algorithm --key-size encryption key size --iter-time Number of millisecond to spend P8KDF passphrase processing --use-random use /dev/random -y verify passphrase  Disk device can now be opened.</description>
    </item>
    
    <item>
      <title>zfs auto snapshot</title>
      <link>https://labs.yulrizka.com/til/linux/zfs-auto-snapshot/</link>
      <pubDate>Mon, 22 Oct 2018 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/linux/zfs-auto-snapshot/</guid>
      <description>Having ZFS snapshot saved me once when I acidentally rm -f /home/myuser.
There is a simple package that easily make auto snapshot.
$ sudo apt install zfs-auto-snapshot  This will install the script and the cron job associated with it.
By default it will backup all filesystem and volumes. You can disable the filesystems completely by
$ sudo zfs set com.sun:auto-snapshot=false tank/data-set-name  or only for specific interval
sudo zfs set com.</description>
    </item>
    
    <item>
      <title>connect bluetooth device from cli</title>
      <link>https://labs.yulrizka.com/til/linux/connect-bluetooth-device-from-cli/</link>
      <pubDate>Sat, 20 Oct 2018 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/linux/connect-bluetooth-device-from-cli/</guid>
      <description>We use bluetoothctl tool which is command-line to BlueZ
$ sudo bluetoothctl  Enable authentication agent
[bluetooth]# agent on  Run the scan process
[bluetooth]# scan on  Pair with the device
[bluetooth]# pair 00:25:56:D1:36:6B  Connect to the device
[bluetooth]# connect 00:25:56:D1:36:6B  more information https://docs.ubuntu.com/core/en/stacks/bluetooth/bluez/docs/reference/pairing/outbound</description>
    </item>
    
    <item>
      <title>diff output of 2 command</title>
      <link>https://labs.yulrizka.com/til/unix/diff-output-of-2-command/</link>
      <pubDate>Thu, 04 Oct 2018 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/diff-output-of-2-command/</guid>
      <description>for example, I want to compare output of 2 different curl comand
$ diff &amp;lt;(curl -s http://host.com/a) &amp;lt;(curl -s http://anotherhost.com/a)  </description>
    </item>
    
    <item>
      <title>get full argument from a process</title>
      <link>https://labs.yulrizka.com/til/linux/get-full-argument-from-a-process/</link>
      <pubDate>Tue, 05 Dec 2017 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/linux/get-full-argument-from-a-process/</guid>
      <description>We can find it out by using ps. For example
$ ps aux | grep cassandra ... cassand+ 24615 40.5 41.9 12064088 5033964 ? SLl 14:28 5:15 java -ea -javaagent:/usr/share/cassandra/lib/jamm-0.3.0.jar -XX:+CMSClassUnloadingEnabled -XX:+UseThreadPriorities -XX:ThreadPriorityPolicy=42 -Xms4096M -Xmx4096M -Xmn1024M -XX:+PreserveFramePointer -Xss256k -XX:StringTableSize=1000003 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:SurvivorRatio=2 -XX:MaxTenuringThreshold=15 -XX:CMSInitiatingOccupancyFraction=25 -XX:+UseCMSInitiatingOccupancyOnly -XX:+UseTLAB -XX:CompileCommandFile=/etc/cassandra/hotspot_compiler -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark -XX:+UnlockDiagnosticVMOptions -XX:-UseBiasedLocking -XX:+UseGCTaskAffinity -XX:+BindGCTaskThreadsToCPUs -XX:ConcGCThreads=16 -XX:ParallelGCThreads=16 -XX:ParGCCardsPerStrideChunk=4096 -XX:+ParallelRefProcEnabled -XX:CMSMaxAbortablePrecleanTime=60000 -XX:CMSWaitDuration=30000 -XX:+AlwaysPreTouch -XX:+UseTLAB -XX:+ResizeTLAB -Dcassandra.max_local_pause_in_ms=40000 -XX:+CMSParallelInitialMarkEnabled -XX:+CMSEdenChunksRecordAlways -XX:+UseCondCardMark -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -XX:+PrintTenuringDistribution -XX:+PrintGCApplicationStoppedTime -XX:+PrintPromotionFailure -XX:PrintFLSStatistics=1 -XX:+PrintAdaptiveSizePolicy -XX:+PrintSafepointStatistics -XX:+PrintClassHistogramBeforeFullGC -XX:+PrintClassHistogramAfterFullGC -Xloggc:/var/log/cassandra/gc.</description>
    </item>
    
    <item>
      <title>sending curl POST with file</title>
      <link>https://labs.yulrizka.com/til/unix/sending-curl-post-with-file/</link>
      <pubDate>Sun, 15 Oct 2017 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/sending-curl-post-with-file/</guid>
      <description>curl -X POST -d @myfilename http://www.url.com `` or `` curl -XPOST &#39;localhost:9200/bank/_search?pretty&#39; -d &#39; { &amp;quot;query&amp;quot;: { &amp;quot;match_phrase&amp;quot;: { &amp;quot;address&amp;quot;: &amp;quot;mill lane&amp;quot; } } }&#39;  </description>
    </item>
    
    <item>
      <title>jq extracting properties to arrays from JSON row line</title>
      <link>https://labs.yulrizka.com/til/unix/jq-extracting-properties-to-arrays-from-json-row-line/</link>
      <pubDate>Mon, 09 Oct 2017 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/jq-extracting-properties-to-arrays-from-json-row-line/</guid>
      <description>For example if we have a file that contains JSON object like
{&amp;quot;a&amp;quot;: 1, &amp;quot;b&amp;quot;:{&amp;quot;c&amp;quot;: 11} {&amp;quot;a&amp;quot;: 2, &amp;quot;b&amp;quot;:{&amp;quot;c&amp;quot;: 22}} {&amp;quot;a&amp;quot;: 3, &amp;quot;b&amp;quot;:{&amp;quot;c&amp;quot;: 33}}  And you want to construct something like
[&amp;quot;1&amp;quot;, &amp;quot;11&amp;quot;] [&amp;quot;2&amp;quot;, &amp;quot;22&amp;quot;] [&amp;quot;3&amp;quot;, &amp;quot;33&amp;quot;]  You can do that with jq
$ cat filename.json | jq -c &#39;[.a, .b.c]&#39;  this is particularly usefull to grep something from JSON log</description>
    </item>
    
    <item>
      <title>list open port</title>
      <link>https://labs.yulrizka.com/til/osx/list-open-port/</link>
      <pubDate>Thu, 16 Mar 2017 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/osx/list-open-port/</guid>
      <description> list open port $ sudo netstat -atp tcp| grep -i listen  or
$ sudo lsof -i -P | grep -i listen  </description>
    </item>
    
    <item>
      <title>parsing epoch timestamp to date</title>
      <link>https://labs.yulrizka.com/til/unix/parsing-epoch-timestamp-to-date/</link>
      <pubDate>Tue, 16 Aug 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/parsing-epoch-timestamp-to-date/</guid>
      <description>To get current unix timestamp we can do
$ date +%s 1471365644  But how do we parse a file which contain epoch timestamp to date?
$ echo 1471365644 | perl -pe &#39;s/(\d+)/localtime($1)/e&#39;  if we have it in milliseconds, we could remove the milliseconds part with
$ echo 1471365644000 | cut -c -10 | perl -pe &#39;s/(\d+)/localtime($1)/e&#39; Tue Aug 16 18:40:44 2016  Assuming your epoch seconds is 10 character.</description>
    </item>
    
    <item>
      <title>repeat content of text x time</title>
      <link>https://labs.yulrizka.com/til/unix/repeat-content-of-text-x-time/</link>
      <pubDate>Mon, 15 Aug 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/repeat-content-of-text-x-time/</guid>
      <description>I have a use-case where 1 have single file that contain 20K line. I need to have another file with 1 million line with just content of the first file repeated 50 time.
Solution: form stack overflow
$ perl -0777pe &#39;$_=$_ x 50&#39; input_file.txt &amp;gt; output_file.txt  arguments:
 0777 : -0 sets sets the input record separator (perl special variable $/ which is a newline by default). Setting this to a value greater than 0400 will cause Perl to slurp the entire input file into memory.</description>
    </item>
    
    <item>
      <title>paste yanked text on command buffer</title>
      <link>https://labs.yulrizka.com/til/vim/paste-yanked-text-on-command-buffer/</link>
      <pubDate>Fri, 12 Aug 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/vim/paste-yanked-text-on-command-buffer/</guid>
      <description>Sometimes you need to paste yanked text while performing command. For example subtituting yanked text with some words.
yanked text are stored in the 0 and &amp;quot; register.
in the command mode you can paste this with ctrl-R [registe] example in our cases this would be ctrl-R 0
so full command would be for example :%s/[press ctrl-R then 0]/replacement/gc</description>
    </item>
    
    <item>
      <title>bulk renaming multiple file</title>
      <link>https://labs.yulrizka.com/til/unix/bulk-renaming-multiple-file/</link>
      <pubDate>Tue, 12 Jul 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/bulk-renaming-multiple-file/</guid>
      <description>There are couple of way to rename multiple files.
From http://unix.stackexchange.com/questions/1136/batch-renaming-files
example we have files
image0001.png image0002.png image0003.png ...  And we would like to rename it to
0001.png 0002.png 0003.png ...  with for loop this works with linux and mac without installing anything
1  for f in *.png; do mv &amp;#34;$f&amp;#34; &amp;#34;${f#image}&amp;#34;; done   With ZSH This is my favorite way since I&amp;rsquo;m using ZSH and oh-my-zsh.</description>
    </item>
    
    <item>
      <title>specify compression level in tar gzip</title>
      <link>https://labs.yulrizka.com/til/unix/specify-compression-level-in-tar-gzip/</link>
      <pubDate>Thu, 30 Jun 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/specify-compression-level-in-tar-gzip/</guid>
      <description>from http://superuser.com/questions/305128/how-to-specify-level-of-compression-when-using-tar-zcvf
GZIP=-9 tar cvzf file.tar.gz /path/to/directory  or
tar cvf - /path/to/file0 /path/to/file1 | gzip -9 - &amp;gt; files.tar.gz  </description>
    </item>
    
    <item>
      <title>clearing up swap space</title>
      <link>https://labs.yulrizka.com/til/linux/clearing-up-swap-space/</link>
      <pubDate>Wed, 15 Jun 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/linux/clearing-up-swap-space/</guid>
      <description>WARNING: make sure the memory is enough to put the data back from swap, else system will start killing processes
To clear up swap space (put the data back into memory) we can do
# swapoff -a &amp;amp;&amp;amp; swapon -a  Because this is quite slow process, it&amp;rsquo;s a good idea to run this inside screen session.</description>
    </item>
    
    <item>
      <title>convert json perline to panads data frame</title>
      <link>https://labs.yulrizka.com/til/analytics/convert-json-perline-to-panads-data-frame/</link>
      <pubDate>Tue, 07 Jun 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/analytics/convert-json-perline-to-panads-data-frame/</guid>
      <description>Sometimes we have a file that contains a json object per line. For example log file in json format
{foo: 1, bar: 2} {foo: 3, bar: 4}  if we want to read this in python pandas we need to convert it to
[ {foo: 1, bar: 2}, {foo: 3, bar: 4} ]  easy way to do this is with jq --slurp
$ cat file.json | jq --slurp . &amp;gt; one_array.</description>
    </item>
    
    <item>
      <title>pandas - format custom date in data frame</title>
      <link>https://labs.yulrizka.com/til/analytics/pandas-format-custom-date-in-data-frame/</link>
      <pubDate>Tue, 07 Jun 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/analytics/pandas-format-custom-date-in-data-frame/</guid>
      <description>say you have a data frame like this
[ {foo: 1, created_date:&amp;quot;2016-06-04 03:00:01.727&amp;quot;}, ... ]  the timestamp doesn&amp;rsquo;t recognize immediately. To make this field as timestamp and as index we could do
1 2 3  # assuming df contains the data frame df[&amp;#39;timestamp&amp;#39;] = pd.to_datetime(be.timestamp, format=&amp;#34;%Y-%m-%d%H:%M:%S.%f&amp;#34;) df.set_index(df[&amp;#39;timestamp&amp;#39;], inplace=True)  </description>
    </item>
    
    <item>
      <title>file size older than x days</title>
      <link>https://labs.yulrizka.com/til/unix/file-size-older-than-x-days/</link>
      <pubDate>Mon, 06 Jun 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/file-size-older-than-x-days/</guid>
      <description>from http://stackoverflow.com/a/17419690/546750
to list all file that modified more than more than X days, we can use
$ find . -mtime +[number of days]  if you use - sign than it became file is modified since X days
Combine it with akw, we can get total file size
$ find . -mtime +180 -exec du -ks {} \; | cut -f1 | awk &#39;{total=total+$1}END{print total/1024}&#39;  </description>
    </item>
    
    <item>
      <title>symbolic vs hard link</title>
      <link>https://labs.yulrizka.com/til/linux/symbolic-vs-hard-link/</link>
      <pubDate>Wed, 01 Jun 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/linux/symbolic-vs-hard-link/</guid>
      <description>from http://stackoverflow.com/a/185903/546750
 Underneath the file system files are represented by inodes (or is it multiple inodes not sure)
A file in the file system is basically a link to an inode. A hard link then just creates another file with a link to the same underlying inode.
When you delete a file it removes one link to the underlying inode. The inode is only deleted (or deletable/over-writable) when all links to the inode have been deleted.</description>
    </item>
    
    <item>
      <title>filtering json with jq</title>
      <link>https://labs.yulrizka.com/til/unix/filtering-json-with-jq/</link>
      <pubDate>Tue, 31 May 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/filtering-json-with-jq/</guid>
      <description>jq is a fantastic command line tools to parse and filter json in command line. It works for linux, osx and maybe windows.
example, to format json
$ json=&#39;[{&amp;quot;genre&amp;quot;:&amp;quot;deep house&amp;quot;}, {&amp;quot;genre&amp;quot;: &amp;quot;progressive house&amp;quot;}, {&amp;quot;genre&amp;quot;: &amp;quot;dubstep&amp;quot;}]&#39; $ echo $json [{&amp;quot;genre&amp;quot;:&amp;quot;deep house&amp;quot;}, {&amp;quot;genre&amp;quot;: &amp;quot;progressive house&amp;quot;}, {&amp;quot;genre&amp;quot;: &amp;quot;dubstep&amp;quot;}] $ echo $json | jq . [ { &amp;quot;genre&amp;quot;: &amp;quot;deep house&amp;quot; }, { &amp;quot;genre&amp;quot;: &amp;quot;progressive house&amp;quot; }, { &amp;quot;genre&amp;quot;: &amp;quot;dubstep&amp;quot; } ]  To output a particular field</description>
    </item>
    
    <item>
      <title>keep N recent item in folder</title>
      <link>https://labs.yulrizka.com/til/unix/keep-n-recent-item-in-folder/</link>
      <pubDate>Thu, 26 May 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/keep-n-recent-item-in-folder/</guid>
      <description>Sometimes you create a script that generate something but you wanted to only keep N last item. There is couple way to achive this. This version works both on OSX and Linux.
$ (ls -t|head -n 5;ls)|sort|uniq -u|xargs rm  Basically it the (..) will capture together the output
 ls -t | head -n 5 will list files sort by time and get first 5 items The second ls will list all file.</description>
    </item>
    
    <item>
      <title>starting program on startup with login items</title>
      <link>https://labs.yulrizka.com/til/osx/starting-program-on-startup-with-login-items/</link>
      <pubDate>Wed, 25 May 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/osx/starting-program-on-startup-with-login-items/</guid>
      <description>I need to start jumpcut during startup because I have to start it manually now.
We can add one or more program to start when we are logged in. Use system preference &amp;gt; Users &amp;amp; Groups. Select your username and there should be Login items tabs where you can add more or disable programs.</description>
    </item>
    
    <item>
      <title>find out what is using swap</title>
      <link>https://labs.yulrizka.com/til/unix/find-out-what-is-using-swap/</link>
      <pubDate>Tue, 24 May 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/find-out-what-is-using-swap/</guid>
      <description>from http://northernmost.org/blog/find-out-what-is-using-your-swap/
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  #!/bin/bash # Get current swap usage for all running processes # Erik Ljungstrom 27/05/2011 SUM=0 OVERALL=0 for DIR in `find /proc/ -maxdepth 1 -type d | egrep &amp;#34;^/proc/[0-9]&amp;#34;` ; do PID=`echo $DIR | cut -d / -f 3` PROGNAME=`ps -p $PID -o comm --no-headers` for SWAP in `grep Swap $DIR/smaps 2&amp;gt;/dev/null| awk &amp;#39;{ print $2 }&amp;#39;` do let SUM=$SUM+$SWAP done echo &amp;#34;PID=$PID- Swap used: $SUM- ($PROGNAME)&amp;#34; let OVERALL=$OVERALL+$SUM SUM=0 done echo &amp;#34;Overall swap used: $OVERALL&amp;#34;  </description>
    </item>
    
    <item>
      <title>prompt confirmation in bash</title>
      <link>https://labs.yulrizka.com/til/unix/prompt-confirmation-in-bash/</link>
      <pubDate>Tue, 24 May 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/prompt-confirmation-in-bash/</guid>
      <description>From http://stackoverflow.com/questions/1885525/how-do-i-prompt-a-user-for-confirmation-in-bash-script
1 2 3 4 5 6  read -p &amp;#34;Are you sure? &amp;#34; -n 1 -r echo # (optional) move to a new line if [[ ! $REPLY =~ ^[Yy]$ ]] then exit 1 fi  </description>
    </item>
    
    <item>
      <title>get all line except n last one</title>
      <link>https://labs.yulrizka.com/til/unix/get-all-line-except-n-last-one/</link>
      <pubDate>Wed, 18 May 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/get-all-line-except-n-last-one/</guid>
      <description>with head -n &amp;lt;negative number&amp;gt; we can get the output except n lines
example
cat a.txt | head -n -1  will gives as the content of a.txt except the last one
Let say we have file 1 2 3 4 5, and with grep we want to only get 1 2 3.
we can achive this with ls and grep
$ ls | grep 4 -B 100000000 | head -n -1  the -B show 100000000 lines before matched line, and the head -n -1 removes the matched</description>
    </item>
    
    <item>
      <title>sign application with self certificate</title>
      <link>https://labs.yulrizka.com/til/osx/sign-application-with-self-certificate/</link>
      <pubDate>Mon, 04 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/osx/sign-application-with-self-certificate/</guid>
      <description>When compiling binary that open port, (depending on your settings) it will ask to allow if the process can make the connection.
We can sign our binary with certificate to avoid this.
From http://apple.stackexchange.com/questions/3271/how-to-get-rid-of-firewall-accept-incoming-connections-dialog/121010#121010
While RedYeti&amp;rsquo;s link is useful, just to save a few clicks for others let me recap how to generate a code-signing cert and to use it for code (re-)signing:
1. Create your own code signing cert: In Keychain Access, Keychain Access &amp;gt; Certificate Assistant &amp;gt; Create a certificate.</description>
    </item>
    
    <item>
      <title>git mergetool and diff with p4merge</title>
      <link>https://labs.yulrizka.com/til/git/git-mergetool-and-diff-with-p4merge/</link>
      <pubDate>Sun, 03 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/git/git-mergetool-and-diff-with-p4merge/</guid>
      <description>Some time you want visually merge conflict in git. To use p4merge https://www.perforce.com/products/helix-core-apps/merge-diff-tool-p4merge
git mergetool Linux $ git config --global merge.tool p4mergetool $ git config --global mergetool.p4mergetool.cmd \ $ &amp;quot;/opt/p4v/bin/p4merge \$PWD/\$BASE \$PWD/\$REMOTE \$PWD/\$LOCAL \$PWD/\$MERGED&amp;quot; $ git config --global mergetool.p4mergetool.trustExitCode false $ git config --global mergetool.keepBackup false  Mac $ git config --global merge.tool p4mergetool $ git config --global mergetool.p4mergetool.cmd \ &amp;quot;/Applications/p4merge.app/Contents/Resources/launchp4merge \$PWD/\$BASE \$PWD/\$REMOTE \$PWD/\$LOCAL \$PWD/\$MERGED&amp;quot; $ git config --global mergetool.</description>
    </item>
    
    <item>
      <title>worktree - switching branch without stash</title>
      <link>https://labs.yulrizka.com/til/git/worktree-switching-branch-without-stash/</link>
      <pubDate>Sun, 03 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/git/worktree-switching-branch-without-stash/</guid>
      <description>Some times you are working on some feature but then you need to check or fix something on some other branch. The normal way to do it is that we do:
 git stash switch to other branch commit changes swith to previous branch git stash pop  This can be complicated especially you have multiple stash. You can&amp;rsquo;t easily understand which stash belongs where.
After version 2.5.2 there is new command called git worktree</description>
    </item>
    
    <item>
      <title>cluster ssh in iterm2 with i2cssh</title>
      <link>https://labs.yulrizka.com/til/osx/cluster-ssh-in-iterm2-with-i2cssh/</link>
      <pubDate>Thu, 31 Mar 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/osx/cluster-ssh-in-iterm2-with-i2cssh/</guid>
      <description>I&amp;rsquo;m a fan of cluster ssh. It allows you to control multiple ssh session with one keyboard. I tried csshx which uses the default osx terminal, but I love iterm2.
But today I found i2cssh which does that for iterm2
One of the feature is broadcast where you can send command to multiple window. It&amp;rsquo;s basically the same with csshx but their approach is to create another extra window that receive an input and send it to all other windows.</description>
    </item>
    
    <item>
      <title>Format or parse json in command line</title>
      <link>https://labs.yulrizka.com/til/unix/formatting-or-parse-json-in-command-line/</link>
      <pubDate>Thu, 17 Mar 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/formatting-or-parse-json-in-command-line/</guid>
      <description>To easily format json or command line there jq
example
$ echo &#39;{&amp;quot;user&amp;quot;:&amp;quot;stedolan&amp;quot;,&amp;quot;titles&amp;quot;:[&amp;quot;JQ Primer&amp;quot;, &amp;quot;More JQ&amp;quot;]}&#39; | jq . { &amp;quot;user&amp;quot;: &amp;quot;stedolan&amp;quot;, &amp;quot;titles&amp;quot;: [ &amp;quot;JQ Primer&amp;quot;, &amp;quot;More JQ&amp;quot; ] }  or just print specific value
$ echo &#39;{&amp;quot;user&amp;quot;:&amp;quot;stedolan&amp;quot;,&amp;quot;titles&amp;quot;:[&amp;quot;JQ Primer&amp;quot;, &amp;quot;More JQ&amp;quot;]}&#39; | jq .titles[0] &amp;quot;JQ Primer&amp;quot;  </description>
    </item>
    
    <item>
      <title>grep - print only matched</title>
      <link>https://labs.yulrizka.com/til/unix/grep-print-only-matched/</link>
      <pubDate>Wed, 16 Mar 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/grep-print-only-matched/</guid>
      <description>you can use the -o flag to only print matched value. Example
$ echo &amp;quot;Hello fellow unix fan&amp;quot; | grep --color -o nix nix $ echo &amp;quot;Hello fellow unix fan&amp;quot; | grep --color -o nux $ echo $? 1  </description>
    </item>
    
    <item>
      <title>send slack message from command line</title>
      <link>https://labs.yulrizka.com/til/unix/send-slack-message-from-command-line/</link>
      <pubDate>Tue, 15 Mar 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/send-slack-message-from-command-line/</guid>
      <description>Install Incomming webhook to your channel https://api.slack.com/incoming-webhooks#sending_messages
you will then get some url https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX
create /usr/local/bin/notifyme
#!/bin/sh curl -X POST --data-urlencode &amp;quot;payload={\&amp;quot;channel\&amp;quot;: \&amp;quot;#alert\&amp;quot;, \&amp;quot;username\&amp;quot;: \&amp;quot;mybot\&amp;quot;, \&amp;quot;text\&amp;quot;: \&amp;quot;$*\&amp;quot;, \&amp;quot;icon_emoji\&amp;quot;: \&amp;quot;:name_badge:\&amp;quot;}&amp;quot; https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX  and send message via your command line
$ chmod +x /usr/local/bin/notifyme $ notifyme hello world! # or after some command $ sleep 5; notifyme process is finished  </description>
    </item>
    
    <item>
      <title>Default math.rand.Source is thread save while rand.New(Source) is not</title>
      <link>https://labs.yulrizka.com/til/go/default-math.rand.source-is-thread-save-while-rand.newsource-is-not/</link>
      <pubDate>Sun, 13 Mar 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/go/default-math.rand.source-is-thread-save-while-rand.newsource-is-not/</guid>
      <description>Default pacakge rand uses Source that is thread safe with default seed 1
we can use the pacakge&amp;rsquo;s method to have thread safe random number generation
1 2 3 4 5 6 7 8 9 10 11 12 13  package main import ( &amp;#34;fmt&amp;#34; &amp;#34;math/rand&amp;#34; &amp;#34;time&amp;#34; ) func main() { seed := time.Now().UnixNano() rand.Seed(seed) fmt.Println(rand.Int63()) }   But the rand.NewSource() offers thread unsafe implementation. One of the reason to choose the unsafe implementation to avoid synchronization, especially when you have only single go routine.</description>
    </item>
    
    <item>
      <title>Removing old kernel</title>
      <link>https://labs.yulrizka.com/til/linux/removing-old-kernel/</link>
      <pubDate>Sat, 12 Mar 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/linux/removing-old-kernel/</guid>
      <description>When upgrading ubuntu, sometimes it failed because of insufficient disk on boot. This could be caused by too many kernel installed on the machine.
Command to remove old kernel from here
dpkg --list | grep linux-image | awk &#39;{ print $2 }&#39; | sort -V | sed -n &#39;/&#39;`uname -r`&#39;/q;p&#39; | xargs sudo apt-get -y purge  dpkg &amp;ndash;list | grep linux-image | awk &amp;lsquo;{ print $2 }&amp;rsquo; | sort -V | sed -n &amp;lsquo;/&amp;rsquo;uname -r&amp;rsquo;/q;p&amp;rsquo; | xargs sudo apt-get -y purgenation (remember, | uses the output of the previous command as the input to the next)</description>
    </item>
    
    <item>
      <title>Reusing last command arguments</title>
      <link>https://labs.yulrizka.com/til/unix/reusing-last-command-argument/</link>
      <pubDate>Fri, 11 Mar 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/reusing-last-command-argument/</guid>
      <description>1 2 3 4 5 6 7 8 9 10  $ echo 1 1 $ echo 2 2 $ echo 3 3 $ echo 4 4 $ echo 5 5   use alt + . will reuse the last program argument in descending order
$ echo (press alt + .) $ echo 5 (press alt + . again) $ echo 4 (press alt + . again) ...  selective arguments  !</description>
    </item>
    
    <item>
      <title>pbcopy alternative for copying to clipboard</title>
      <link>https://labs.yulrizka.com/til/unix/pbcopy-alternative-for-copying-to-clipboard/</link>
      <pubDate>Sat, 13 Feb 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/pbcopy-alternative-for-copying-to-clipboard/</guid>
      <description>in osx we have pbcopy &amp;amp; pbpaste
we can have something similar in linux. Put this is your shell profile (~/.bashrc or ~/.zshrc if you are using zsh)
1 2  alias pbcopy=&amp;#39;xclip -selection clipboard&amp;#39; alias pbpaste=&amp;#39;xclip -selection clipboard -o&amp;#39;  </description>
    </item>
    
    <item>
      <title>manage clipboard easily with jumpcut</title>
      <link>https://labs.yulrizka.com/til/osx/manage-clipboard-easily-with-jumpcut/</link>
      <pubDate>Thu, 11 Feb 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/osx/manage-clipboard-easily-with-jumpcut/</guid>
      <description>Jumpcut is clipboard manager that allows you to select your copy history.
Let say you copy fil the contents of A, B, C, D. After you copy file D you want to paste the file B. Usually you have to go back to copy the content of file, but now you don&amp;rsquo;t have too.</description>
    </item>
    
    <item>
      <title>pipe output to clipboard with pbcopy and pbpaste</title>
      <link>https://labs.yulrizka.com/til/osx/pipe-output-to-clipboard-with-pbcopy-and-pbpaste/</link>
      <pubDate>Wed, 10 Feb 2016 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/osx/pipe-output-to-clipboard-with-pbcopy-and-pbpaste/</guid>
      <description>Using terminal and needs to copy the result of command to clipboard ? use pbcopy
1  $ cat somefile.txt | pbcopy   Or the other way around, paste from clipboard and pipe it to other program
1  $ pbpaste | grep foo  </description>
    </item>
    
    <item>
      <title>Testing go 1.5 cross compilation on raspberry pi</title>
      <link>https://labs.yulrizka.com/en/testing-go-1-dot-5-cross-compilation/</link>
      <pubDate>Sat, 29 Aug 2015 17:28:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/en/testing-go-1-dot-5-cross-compilation/</guid>
      <description>I&amp;rsquo;m so excited with the new release of golang. One particular feature is now very easy to build for multiple architecture. If you seen my other posts, I also like to tinker with my raspberry-pi. On my previous project I use either ruby or python for building some stuff. One annoying thing is dependency, setup and compilation is usually quite slow. Would be cool if I could just create some stuff in desktop and just scp the binary to pi and everything should work!</description>
    </item>
    
    <item>
      <title>osx-push-to-talk App</title>
      <link>https://labs.yulrizka.com/en/osx-push-to-talk-app/</link>
      <pubDate>Sun, 22 Mar 2015 00:26:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/en/osx-push-to-talk-app/</guid>
      <description>Push To Talk app for OSX
PushToTalk App installer   As a part of scrum teams, every day I need to give updates to my team via Google Hangout. We have a team here in the Netherlands and also in Indonesia. Some times I am in the same room as a colleague of mine. This sometimes quite annoying because I can hear my self (with a delay) from his mic.</description>
    </item>
    
    <item>
      <title>process pipe operator</title>
      <link>https://labs.yulrizka.com/til/unix/process-pipe-operator/</link>
      <pubDate>Thu, 12 Feb 2015 00:00:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/til/unix/process-pipe-operator/</guid>
      <description>&amp;lt;( ) operator executes command inside the parenthesis and output the file descriptor
example
1 2 3 4 5 6 7 8 9 10 11 12 13  $ cat &amp;lt;(echo &amp;#39;hello&amp;#39;) &amp;lt;(echo &amp;#39;world&amp;#39;) hello world # is practically the same with $ echo &amp;#39;hello&amp;#39; &amp;gt; 1.txt $ echo &amp;#39;world&amp;#39; &amp;gt; 2.txt $ cat 1.txt 2.txt # replace cat with ls $ ls &amp;lt;(echo &amp;#39;hello&amp;#39;) &amp;lt;(echo &amp;#39;world&amp;#39;) /proc/self/fd/11 /proc/self/fd/12   you can use this command for example to compare 2 directory and find only uniq file</description>
    </item>
    
    <item>
      <title>Tracking origin of bugs with git bisect</title>
      <link>https://labs.yulrizka.com/en/tracking-origin-of-bugs-with-git-bisect/</link>
      <pubDate>Fri, 16 Jan 2015 23:35:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/en/tracking-origin-of-bugs-with-git-bisect/</guid>
      <description>Disect the rocket, image by ProudloveNathan Proudlove  I&amp;rsquo;ve been involved with a iOS project this past week. I&amp;rsquo;m adding functionalities to the CommonSense iOS library. One of the most annoying thing is that it took about 2 minute to load the project. This is only happened in the unstable branch. The master branch seems to be working fine. So I knew that somewhere there is a commit when this starts happening.</description>
    </item>
    
    <item>
      <title>Stubbing Time.Now() in golang</title>
      <link>https://labs.yulrizka.com/en/stubbing-time-dot-now-in-golang/</link>
      <pubDate>Mon, 27 Oct 2014 16:42:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/en/stubbing-time-dot-now-in-golang/</guid>
      <description>Some time it&amp;rsquo;s really hard to test functionality that involves with system time. Especially when we wanted to test specific functionality. For example testing whether today is end of month. It&amp;rsquo;s unrealistic to run this test case once every month.
I can think of multiple ways to address this issue. It depends on the use case where it may apply to the use-cases
Passing the time object 1 2 3  func CheckEndOfMonth(now time.</description>
    </item>
    
    <item>
      <title>My account just got hacked by Romanian (Possibly)</title>
      <link>https://labs.yulrizka.com/en/my-account-just-got-hacked-by-romanian-possibly/</link>
      <pubDate>Sat, 27 Jul 2013 11:58:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/en/my-account-just-got-hacked-by-romanian-possibly/</guid>
      <description>You are probably familiar with above images. Some random friend sent you an email which you can instantly recognize as a spam because it only contains one link. Couple days ago I receive this email which is not the first time for me. But this time it was different. It actually came from my own Yahoo! account which I never use since more that one year ago.
My first instinct is to check whether the mail really got sent from my account or it just spoofing my email address.</description>
    </item>
    
    <item>
      <title>berks upload core dump</title>
      <link>https://labs.yulrizka.com/en/berks-upload-ruby-core-dump/</link>
      <pubDate>Sun, 21 Jul 2013 23:26:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/en/berks-upload-ruby-core-dump/</guid>
      <description>Berksfhel is cookbook dependency for chef. If you are familiar with ruby / python, think of it as a Bundler or virtual environment for chef
I faced this core dump error while doing berks upload. That command will actualy push some cookbook to a chef server.
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  $ berks upload /home/user/.rbenv/versions/1.9.3-p362/lib/ruby/gems/1.9.1/gems/celluloid-0.14.1/lib/celluloid/tasks.rb:47: [BUG] Segmentation fault ruby 1.</description>
    </item>
    
    <item>
      <title>Safely sharing credentials with PGP</title>
      <link>https://labs.yulrizka.com/en/safely-sharing-credentials-with-pgp/</link>
      <pubDate>Mon, 08 Jul 2013 16:24:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/en/safely-sharing-credentials-with-pgp/</guid>
      <description>When working in teams, we are sometimes required to share some password / keys with our team. The most common way for me is probably through email or some chat client. But even though its convenience it&amp;rsquo;s not actually a secure and a good practice. Especially if you are providing a service that deal with sensitive information.
Some simple approach would we communicating the password directly with a person through secure medium.</description>
    </item>
    
    <item>
      <title>Homeward light indicator with RaspberryPi and CommonSense</title>
      <link>https://labs.yulrizka.com/en/homeward-light-indicator-with-raspberrypi-and-commonsense/</link>
      <pubDate>Tue, 26 Feb 2013 20:33:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/en/homeward-light-indicator-with-raspberrypi-and-commonsense/</guid>
      <description>I&amp;rsquo;ve been tinkering with my raspberry-pi for quite some time now. What I like about it because it is cheap ($25), it&amp;rsquo;s run Linux (especially debian based) and most of all it&amp;rsquo;s have General Purpose Input Output pin. Since I was a kid, I always wanted to control electronic appliance remotely. Luckily my friend @pimnijdam thought me how to control a relay board. Basically it&amp;rsquo;s just like an electric switch that connect/disconnect current when you supply a low voltage.</description>
    </item>
    
    <item>
      <title>Responsive Design</title>
      <link>https://labs.yulrizka.com/en/responsive-design/</link>
      <pubDate>Fri, 24 Feb 2012 01:48:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/en/responsive-design/</guid>
      <description>I&amp;rsquo;ve been playing around with twitter bootstrap. It&amp;rsquo;s like a css framework to help designer or developer create a nice and clean site. It&amp;rsquo;s offer grid system, predefine layout, button, javascript, carousel etc. You can build website in just a few hours. Very nice for prototyping.
I&amp;rsquo;ve been using it to build this blog since it was version 1. Recently i had a chance to upgrade it to version 2. The new version offer a lot of functionalities, one the feature that I play a lot is the responsive design.</description>
    </item>
    
    <item>
      <title>Jekyll error utf-8 caracter</title>
      <link>https://labs.yulrizka.com/en/jekyll-error-utf-8-caracter/</link>
      <pubDate>Sat, 14 Jan 2012 17:32:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/en/jekyll-error-utf-8-caracter/</guid>
      <description>If you having a problem in jekyll when it didn&amp;rsquo;t generate a post and there is no error in the log file. you might want to check the content if there is any UTF-8 character encoding such as this Â±
The problem arise if you use ruby 1.9. It rejecting a file that contain non-ASCII character. it actually got invalid multibyte char (US-ASCII) error message
to solve this. I added this line to .</description>
    </item>
    
    <item>
      <title>Testing ruby code with benchmark_suite</title>
      <link>https://labs.yulrizka.com/en/testing-ruby-code-with-benchmark-suite/</link>
      <pubDate>Sat, 14 Jan 2012 12:05:00 +0200</pubDate>
      
      <guid>https://labs.yulrizka.com/en/testing-ruby-code-with-benchmark-suite/</guid>
      <description>Just a couple days ago I found out therubygame.com which challenge us to solve a problem with ruby. The result were measured by the fastest, slowest, shortest, longest, cheaters (yup there are also some rule).
And also I was listening to an episode of ruby rouge on Benchmarking. And there is one tools called benchmark_suite.
So there is this challenge to capitalize first letter of every word. I want to compare my code to the fastest solution there.</description>
    </item>
    
    <item>
      <title>Ruby Fiber apaan sih ?</title>
      <link>https://labs.yulrizka.com/id/ruby-fiber-apaan-sih/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://labs.yulrizka.com/id/ruby-fiber-apaan-sih/</guid>
      <description>Fibers are light-weight (green) threads with manual, cooperative scheduling, rather than the preemptive scheduling of Ruby 1.8&#39;s threads. Since Ruby 1.9&#39;s threads exist at the system level, fibers are, in a way, Ruby 1.9&#39;s answer to Ruby 1.8&#39;s green threads, but lacking the pre-emptive scheduling  rubyinside.com    Thread Untuk dapat mengerti mengenai fiber, sebelumnya kita harus memahami thread. Suatu (instance) program yang sedang berjalan disebut dengan proses.</description>
    </item>
    
    <item>
      <title>Scale MongoDB dengan Sharding</title>
      <link>https://labs.yulrizka.com/id/scale-mongodb-dengan-sharding/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://labs.yulrizka.com/id/scale-mongodb-dengan-sharding/</guid>
      <description>TL;DR Proses Horizontal Partitioning pada MongoDB melibatkan suatu konsep Chunk dimana data dibagi menjadi beberapa chunk sesuai dengan suatu shard key. Artikel ini membahas bagaimana melakukan sharding pada mongodb  Introduksi MongoDB adalah salah satu NoSQL database yang cukup populer. MongoDB merupakan document store database, dimana data disimpan dalam format BSON atau mirip dengan JSON. Keunggulan mongoDB antara lain adalah automatic sharding. Artinya apabila kita memiliki beberapa server database, kita dapat melakukan partisi terhadap data tersebut dan mongo akan melakukan load balancing terhadap data tersebut secara automatis</description>
    </item>
    
    <item>
      <title>Telepon murah ke Indonesia dengan voip</title>
      <link>https://labs.yulrizka.com/id/telepon-murah-ke-indonesia-dengan-voip/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://labs.yulrizka.com/id/telepon-murah-ke-indonesia-dengan-voip/</guid>
      <description>Disclaimer: Tulias ini berisi pengalaman penulis menggunakan VoIP dari belanda. Hasilnya mungkin berbeda dengan yang anda peroleh. Penulis tidak bertanggung jawab atas kerugian yang ditimbulkan apabila pembaca memutuskan untuk menggunakan VoIP
   Buat rekan-rekan yang sedang belajar atau bekerja di Belanda, terkadang kita rindu sanak saudra. Sebenarnya banyak cara untuk dapat berbincang dengan keluarga di Indonesia dengan mudah
Servis gratis misalkan:
 Skype Google Hangouts Whatsapp calling  Namun kadang-kadang berkomunikasi dengan aplikasi diatas kadang sulit.</description>
    </item>
    
  </channel>
</rss>